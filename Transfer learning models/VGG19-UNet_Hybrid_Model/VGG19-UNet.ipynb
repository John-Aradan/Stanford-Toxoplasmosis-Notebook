{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNEivV4xVsEN7upMTLU5AbW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"F6aYh_toFG3i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687456038464,"user_tz":-330,"elapsed":4159,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}},"outputId":"2d755bcb-da97-4523-cf78-274e4d4064fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["\"\"\" mount drive to access the dataset\"\"\"\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import VGG19\n","\n","def conv_block(input, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    return x\n","\n","def decoder_block(input, skip_features, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n","    x = Concatenate()([x, skip_features])\n","    x = conv_block(x, num_filters)\n","    return x"],"metadata":{"id":"tiP4nKR8Gyt5","executionInfo":{"status":"ok","timestamp":1687456064782,"user_tz":-330,"elapsed":3874,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\"\"\"metric.py\"\"\"\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","def iou(y_true, y_pred):\n","    def f(y_true, y_pred):\n","        intersection = (y_true * y_pred).sum()\n","        union = y_true.sum() + y_pred.sum() - intersection\n","        x = (intersection + 1e-15) / (union + 1e-15)\n","        x = x.astype(np.float32)\n","        return x\n","    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n","\n","smooth = 1e-15\n","def dice_coef(y_true, y_pred):\n","    y_true = tf.keras.layers.Flatten()(y_true)\n","    y_pred = tf.keras.layers.Flatten()(y_pred)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n","\n","def dice_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred)"],"metadata":{"id":"-T2bxbK0Gzc2","executionInfo":{"status":"ok","timestamp":1687456064783,"user_tz":-330,"elapsed":3,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\"\"\"train.py\"\"\"\n","\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","import numpy as np\n","import cv2\n","from glob import glob\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau # ModelCheckPoint - save weights;\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import Recall, Precision\n","\n","\"\"\" Global parameters \"\"\"\n","H = 512\n","W = 512\n","\n","def create_dir(path):\n","    \"\"\" Create a directory. \"\"\"\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def load_data(split=0.1): # split as 80-10-10 for train-val-test split\n","    images = sorted(glob(os.path.join( \"/content/drive/MyDrive/Stanford-Computer_Vision-Rectina/Image_Dataset/Image\", \"*.jpg\")))                       #\n","    masks = sorted(glob(os.path.join(\"/content/drive/MyDrive/Stanford-Computer_Vision-Rectina/Image_Dataset/Mask\", \"*.jpg\")))        # EDIT ACCORDINGLY\n","\n","    train_x, valid_x = train_test_split(images, test_size=split, random_state=42)\n","    train_y, valid_y = train_test_split(masks, test_size=split, random_state=42)\n","\n","    train_x, test_x = train_test_split(train_x, test_size=split, random_state=42)\n","    train_y, test_y = train_test_split(train_y, test_size=split, random_state=42)\n","\n","    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"],"metadata":{"id":"IXGOy8B6G2GZ","executionInfo":{"status":"ok","timestamp":1687456065989,"user_tz":-330,"elapsed":1209,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def apply_clahe_img(image):\n","    # Convert RGB image to LAB color space\n","    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n","\n","    # Apply CLAHE to the L channel (Lightness)\n","    lab_planes = cv2.split(lab)\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","    lab_planes[0] = clahe.apply(lab_planes[0])\n","\n","    # Merge the enhanced L channel back with the other channels\n","    lab = cv2.merge(lab_planes)\n","\n","    # Convert the LAB image back to RGB color space\n","    enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n","\n","    return enhanced_image\n","\n","def apply_clahe_mask(image):\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","    image = clahe.apply(image)\n","    return image\n","\n","def read_image(path):       # read an image from train_x, or train_y, or... any other data split\n","    x = cv2.imread(path, cv2.IMREAD_COLOR)      # convert it to 3 channel (if grayscale or else colour only) and\n","    x = cv2.resize(x, (W, H))                   # resize image to (512,512,3)\n","    # x = apply_clahe_img(x)\n","    x = x/255.0                                 # normailise to have value bethween 0 and 1\n","    x = x.astype(np.float32)                    # convert to numpy float datatype\n","    return x\n","\n","def read_mask(path):\n","    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","    x = cv2.resize(x, (W, H))\n","    #  x = apply_clahe_mask(x)\n","    x = x/np.max(x)\n","    x = x > 0.5\n","    x = x.astype(np.float32)\n","    x = np.expand_dims(x, axis=-1)          # convert (512,512) to (512,512,1)\n","    return x\n","\n","def tf_parse(x, y):        # this function takes in images x,y\n","    def _parse(x, y):      # calls read_image and read_mask on the image\n","        x = x.decode()\n","        y = y.decode()\n","\n","        x = read_image(x)\n","        y = read_mask(y)\n","        return x, y             # returns as numpy array\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])     # converts numpy array to tensor type\n","    x.set_shape([H, W, 3])\n","    y.set_shape([H, W, 1])\n","    return x, y\n","\n","def tf_dataset(X, Y, batch=8):     # Here X,Y are list containing the images\n","    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n","    dataset = dataset.shuffle(buffer_size=200)  # shuffle the dataset\n","    dataset = dataset.map(tf_parse)     # calls 'tf_parse' function to convert to a tensor\n","    dataset = dataset.batch(batch)      # create a batch of data\n","    dataset = dataset.prefetch(4)       # prefect some data in advance to RAM\n","    return dataset"],"metadata":{"id":"e3t3F1SGG8fi","executionInfo":{"status":"ok","timestamp":1687456935556,"user_tz":-330,"elapsed":828,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    \"\"\" Seeding \"\"\"\n","    np.random.seed(42)          # to ensure that randomness is prevented, simmillar results are produced at later implementations\n","    tf.random.set_seed(42)\n","\n","    \"\"\" Directory for storing files \"\"\"\n","    create_dir(\"files\")\n","\n","    \"\"\" Hyperparameters \"\"\"\n","    batch_size = 4      # to limit number of images eveluvated at once to handle GPU limitations\n","    lr = 1e-5           # learning rate\n","    num_epochs = 20     # number of iteations\n","    model_path = os.path.join(\"files\", \"model.h5\")      # location where model weights from 'ModelCheckpoint' are stored\n","    csv_path = os.path.join(\"files\", \"data.csv\")        # location where model csv details from 'CSVLogger' are stored\n","\n","    \"\"\" Dataset \"\"\"\n","    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data()\n","\n","    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n","    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n","    print(f\"Test: {len(test_x)} - {len(test_y)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfvZOWXDHiNt","executionInfo":{"status":"ok","timestamp":1687456940738,"user_tz":-330,"elapsed":901,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}},"outputId":"2db37024-beca-4495-a814-f9706964852d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 47 - 47\n","Valid: 6 - 6\n","Test: 6 - 6\n"]}]},{"cell_type":"code","source":["    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)   # create train and test dataset out of x_train and y_train\n","    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n","    train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-mVz_4bH2JV","executionInfo":{"status":"ok","timestamp":1687456944977,"user_tz":-330,"elapsed":859,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}},"outputId":"8095df22-5548-450b-a1c4-c802b1d32bee"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None))>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["    \"\"\"model\"\"\"\n","\n","    def build_vgg19_unet(input_shape):\n","        \"\"\" Input \"\"\"\n","        inputs = Input(input_shape)\n","\n","        \"\"\" Pre-trained VGG19 Model \"\"\"\n","        vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n","\n","        \"\"\" Encoder \"\"\"\n","        s1 = vgg19.get_layer(\"block1_conv2\").output         ## (512 x 512)\n","        s2 = vgg19.get_layer(\"block2_conv2\").output         ## (256 x 256)\n","        s3 = vgg19.get_layer(\"block3_conv4\").output         ## (128 x 128)\n","        s4 = vgg19.get_layer(\"block4_conv4\").output         ## (64 x 64)\n","\n","        \"\"\" Bridge \"\"\"\n","        b1 = vgg19.get_layer(\"block5_conv4\").output         ## (32 x 32)\n","\n","        \"\"\" Decoder \"\"\"\n","        d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n","        d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n","        d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n","        d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n","\n","        \"\"\" Output \"\"\"\n","        outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n","\n","        model = Model(inputs, outputs, name=\"VGG19_U-Net\")\n","        return model\n","\n","    model = build_vgg19_unet((H, W, 3))\n","    metrics = [dice_coef, iou, Recall(), Precision()]\n","    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=metrics)\n","\n","    model.summary()"],"metadata":{"id":"_hSvThXIH6U8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687456949948,"user_tz":-330,"elapsed":2748,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}},"outputId":"bcef1c2f-a412-4a1d-a33b-0291ee207cfb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"VGG19_U-Net\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 512, 512, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," block1_conv1 (Conv2D)          (None, 512, 512, 64  1792        ['input_3[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," block1_conv2 (Conv2D)          (None, 512, 512, 64  36928       ['block1_conv1[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," block1_pool (MaxPooling2D)     (None, 256, 256, 64  0           ['block1_conv2[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," block2_conv1 (Conv2D)          (None, 256, 256, 12  73856       ['block1_pool[0][0]']            \n","                                8)                                                                \n","                                                                                                  \n"," block2_conv2 (Conv2D)          (None, 256, 256, 12  147584      ['block2_conv1[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," block2_pool (MaxPooling2D)     (None, 128, 128, 12  0           ['block2_conv2[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," block3_conv1 (Conv2D)          (None, 128, 128, 25  295168      ['block2_pool[0][0]']            \n","                                6)                                                                \n","                                                                                                  \n"," block3_conv2 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv1[0][0]']           \n","                                6)                                                                \n","                                                                                                  \n"," block3_conv3 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv2[0][0]']           \n","                                6)                                                                \n","                                                                                                  \n"," block3_conv4 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv3[0][0]']           \n","                                6)                                                                \n","                                                                                                  \n"," block3_pool (MaxPooling2D)     (None, 64, 64, 256)  0           ['block3_conv4[0][0]']           \n","                                                                                                  \n"," block4_conv1 (Conv2D)          (None, 64, 64, 512)  1180160     ['block3_pool[0][0]']            \n","                                                                                                  \n"," block4_conv2 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv1[0][0]']           \n","                                                                                                  \n"," block4_conv3 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv2[0][0]']           \n","                                                                                                  \n"," block4_conv4 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv3[0][0]']           \n","                                                                                                  \n"," block4_pool (MaxPooling2D)     (None, 32, 32, 512)  0           ['block4_conv4[0][0]']           \n","                                                                                                  \n"," block5_conv1 (Conv2D)          (None, 32, 32, 512)  2359808     ['block4_pool[0][0]']            \n","                                                                                                  \n"," block5_conv2 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv1[0][0]']           \n","                                                                                                  \n"," block5_conv3 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv2[0][0]']           \n","                                                                                                  \n"," block5_conv4 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv3[0][0]']           \n","                                                                                                  \n"," conv2d_transpose_8 (Conv2DTran  (None, 64, 64, 512)  1049088    ['block5_conv4[0][0]']           \n"," spose)                                                                                           \n","                                                                                                  \n"," concatenate_8 (Concatenate)    (None, 64, 64, 1024  0           ['conv2d_transpose_8[0][0]',     \n","                                )                                 'block4_conv4[0][0]']           \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate_8[0][0]']          \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_16[0][0]']          \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_transpose_9 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_17[0][0]']          \n"," spose)                         6)                                                                \n","                                                                                                  \n"," concatenate_9 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_9[0][0]',     \n","                                2)                                'block3_conv4[0][0]']           \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_9[0][0]']          \n","                                6)                                                                \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 128, 128, 25  1024       ['conv2d_20[0][0]']              \n"," ormalization)                  6)                                                                \n","                                                                                                  \n"," activation_18 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_18[0][0]'] \n","                                6)                                                                \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 128, 128, 25  590080      ['activation_18[0][0]']          \n","                                6)                                                                \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 128, 128, 25  1024       ['conv2d_21[0][0]']              \n"," ormalization)                  6)                                                                \n","                                                                                                  \n"," activation_19 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_19[0][0]'] \n","                                6)                                                                \n","                                                                                                  \n"," conv2d_transpose_10 (Conv2DTra  (None, 256, 256, 12  131200     ['activation_19[0][0]']          \n"," nspose)                        8)                                                                \n","                                                                                                  \n"," concatenate_10 (Concatenate)   (None, 256, 256, 25  0           ['conv2d_transpose_10[0][0]',    \n","                                6)                                'block2_conv2[0][0]']           \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_10[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 256, 256, 12  512        ['conv2d_22[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_20 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_20[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 256, 256, 12  147584      ['activation_20[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 256, 256, 12  512        ['conv2d_23[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_21 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_21[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_transpose_11 (Conv2DTra  (None, 512, 512, 64  32832      ['activation_21[0][0]']          \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," concatenate_11 (Concatenate)   (None, 512, 512, 12  0           ['conv2d_transpose_11[0][0]',    \n","                                8)                                'block1_conv2[0][0]']           \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_11[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 512, 512, 64  256        ['conv2d_24[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_22 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_22[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 512, 512, 64  36928       ['activation_22[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 512, 512, 64  256        ['conv2d_25[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_23 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_23[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 512, 512, 1)  65          ['activation_23[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 31,172,033\n","Trainable params: 31,168,193\n","Non-trainable params: 3,840\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["    # \"\"\"Perform Data Augmentation on train and valid sets\"\"\"\n","\n","    # import numpy as np\n","    # from keras.preprocessing.image import ImageDataGenerator\n","    # from skimage import io\n","\n","    # datagen = ImageDataGenerator(\n","    #         rotation_range=45,     # Random rotation between 0 and 45\n","    #         width_shift_range=0.2,   # % shift\n","    #         height_shift_range=0.2,\n","    #         shear_range=0.2,\n","    #         zoom_range=0.2,\n","    #         horizontal_flip=True,\n","    #         fill_mode='nearest')\n","\n","    # # Convert dataset objects to numpy arrays\n","    # train_images = np.array([train_x for train_x, _ in train_dataset])\n","    # train_labels = np.array([train_y for _, train_y in train_dataset])\n","    # valid_images = np.array([valid_x for valid_x, _ in valid_dataset])\n","    # valid_labels = np.array([valid_y for _, valid_y in valid_dataset])\n","\n","    # # Generate augmented datasets using flow() method\n","    # augmented_train_dataset = datagen.flow(train_images, train_labels, batch_size=5)\n","    # augmented_valid_dataset = datagen.flow(valid_images, valid_labels, batch_size=5)\n"],"metadata":{"id":"YBsmd1cODhc7","executionInfo":{"status":"ok","timestamp":1687456076660,"user_tz":-330,"elapsed":16,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["    callbacks = [                                                                  # defines callbacks\n","        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n","        CSVLogger(csv_path)\n","    ]\n","\n","    model.fit(                                                                     # fits / trains data\n","            train_dataset,\n","            epochs=num_epochs,\n","            validation_data=valid_dataset,\n","            callbacks=callbacks\n","        )"],"metadata":{"id":"NIbH6OD6I-bc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4cf84e09-f05b-4d48-c35d-8f78174e8854"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","12/12 [==============================] - ETA: 0s - loss: 0.8887 - dice_coef: 0.1104 - iou: 0.0591 - recall_2: 0.3956 - precision_2: 0.0788\n","Epoch 1: val_loss improved from inf to 0.90811, saving model to files/model.h5\n","12/12 [==============================] - 29s 1s/step - loss: 0.8887 - dice_coef: 0.1104 - iou: 0.0591 - recall_2: 0.3956 - precision_2: 0.0788 - val_loss: 0.9081 - val_dice_coef: 0.0784 - val_iou: 0.0412 - val_recall_2: 0.1327 - val_precision_2: 0.0369 - lr: 1.0000e-05\n","Epoch 2/20\n","12/12 [==============================] - ETA: 0s - loss: 0.8649 - dice_coef: 0.1343 - iou: 0.0731 - recall_2: 0.5590 - precision_2: 0.1215\n","Epoch 2: val_loss improved from 0.90811 to 0.89969, saving model to files/model.h5\n","12/12 [==============================] - 14s 1s/step - loss: 0.8649 - dice_coef: 0.1343 - iou: 0.0731 - recall_2: 0.5590 - precision_2: 0.1215 - val_loss: 0.8997 - val_dice_coef: 0.0951 - val_iou: 0.0500 - val_recall_2: 0.4685 - val_precision_2: 0.0539 - lr: 1.0000e-05\n","Epoch 3/20\n","12/12 [==============================] - ETA: 0s - loss: 0.8457 - dice_coef: 0.1545 - iou: 0.0849 - recall_2: 0.6724 - precision_2: 0.1465\n","Epoch 3: val_loss improved from 0.89969 to 0.89333, saving model to files/model.h5\n","12/12 [==============================] - 14s 1s/step - loss: 0.8457 - dice_coef: 0.1545 - iou: 0.0849 - recall_2: 0.6724 - precision_2: 0.1465 - val_loss: 0.8933 - val_dice_coef: 0.1010 - val_iou: 0.0533 - val_recall_2: 0.7724 - val_precision_2: 0.0615 - lr: 1.0000e-05\n","Epoch 4/20\n","12/12 [==============================] - ETA: 0s - loss: 0.8213 - dice_coef: 0.1764 - iou: 0.0982 - recall_2: 0.8157 - precision_2: 0.1817\n","Epoch 4: val_loss improved from 0.89333 to 0.88516, saving model to files/model.h5\n","12/12 [==============================] - 14s 1s/step - loss: 0.8213 - dice_coef: 0.1764 - iou: 0.0982 - recall_2: 0.8157 - precision_2: 0.1817 - val_loss: 0.8852 - val_dice_coef: 0.1117 - val_iou: 0.0592 - val_recall_2: 0.9523 - val_precision_2: 0.0625 - lr: 1.0000e-05\n","Epoch 5/20\n","12/12 [==============================] - ETA: 0s - loss: 0.8050 - dice_coef: 0.1935 - iou: 0.1100 - recall_2: 0.8683 - precision_2: 0.2013\n","Epoch 5: val_loss improved from 0.88516 to 0.88176, saving model to files/model.h5\n","12/12 [==============================] - 15s 1s/step - loss: 0.8050 - dice_coef: 0.1935 - iou: 0.1100 - recall_2: 0.8683 - precision_2: 0.2013 - val_loss: 0.8818 - val_dice_coef: 0.1478 - val_iou: 0.0823 - val_recall_2: 0.9888 - val_precision_2: 0.0631 - lr: 1.0000e-05\n","Epoch 6/20\n","12/12 [==============================] - ETA: 0s - loss: 0.7787 - dice_coef: 0.2173 - iou: 0.1256 - recall_2: 0.9361 - precision_2: 0.2304\n","Epoch 6: val_loss improved from 0.88176 to 0.87139, saving model to files/model.h5\n","12/12 [==============================] - 14s 1s/step - loss: 0.7787 - dice_coef: 0.2173 - iou: 0.1256 - recall_2: 0.9361 - precision_2: 0.2304 - val_loss: 0.8714 - val_dice_coef: 0.1259 - val_iou: 0.0672 - val_recall_2: 0.9876 - val_precision_2: 0.0666 - lr: 1.0000e-05\n","Epoch 7/20\n","12/12 [==============================] - ETA: 0s - loss: 0.7548 - dice_coef: 0.2478 - iou: 0.1449 - recall_2: 0.9499 - precision_2: 0.2646\n","Epoch 7: val_loss improved from 0.87139 to 0.86094, saving model to files/model.h5\n","12/12 [==============================] - 14s 1s/step - loss: 0.7548 - dice_coef: 0.2478 - iou: 0.1449 - recall_2: 0.9499 - precision_2: 0.2646 - val_loss: 0.8609 - val_dice_coef: 0.1630 - val_iou: 0.0904 - val_recall_2: 0.9997 - val_precision_2: 0.0655 - lr: 1.0000e-05\n","Epoch 8/20\n","12/12 [==============================] - ETA: 0s - loss: 0.7402 - dice_coef: 0.2589 - iou: 0.1547 - recall_2: 0.9641 - precision_2: 0.2925\n","Epoch 8: val_loss improved from 0.86094 to 0.84626, saving model to files/model.h5\n","12/12 [==============================] - 15s 1s/step - loss: 0.7402 - dice_coef: 0.2589 - iou: 0.1547 - recall_2: 0.9641 - precision_2: 0.2925 - val_loss: 0.8463 - val_dice_coef: 0.1395 - val_iou: 0.0756 - val_recall_2: 0.9993 - val_precision_2: 0.0705 - lr: 1.0000e-05\n","Epoch 9/20\n","12/12 [==============================] - ETA: 0s - loss: 0.7230 - dice_coef: 0.2764 - iou: 0.1647 - recall_2: 0.9579 - precision_2: 0.3378\n","Epoch 9: val_loss did not improve from 0.84626\n","12/12 [==============================] - 13s 1s/step - loss: 0.7230 - dice_coef: 0.2764 - iou: 0.1647 - recall_2: 0.9579 - precision_2: 0.3378 - val_loss: 0.8495 - val_dice_coef: 0.1485 - val_iou: 0.0802 - val_recall_2: 0.9999 - val_precision_2: 0.0691 - lr: 1.0000e-05\n","Epoch 10/20\n","12/12 [==============================] - ETA: 0s - loss: 0.7054 - dice_coef: 0.2914 - iou: 0.1755 - recall_2: 0.9520 - precision_2: 0.3643\n","Epoch 10: val_loss improved from 0.84626 to 0.82000, saving model to files/model.h5\n","12/12 [==============================] - 14s 1s/step - loss: 0.7054 - dice_coef: 0.2914 - iou: 0.1755 - recall_2: 0.9520 - precision_2: 0.3643 - val_loss: 0.8200 - val_dice_coef: 0.1776 - val_iou: 0.0974 - val_recall_2: 0.9900 - val_precision_2: 0.1124 - lr: 1.0000e-05\n","Epoch 11/20\n","12/12 [==============================] - ETA: 0s - loss: 0.6935 - dice_coef: 0.3063 - iou: 0.1876 - recall_2: 0.9574 - precision_2: 0.4003\n","Epoch 11: val_loss improved from 0.82000 to 0.81564, saving model to files/model.h5\n","12/12 [==============================] - 15s 1s/step - loss: 0.6935 - dice_coef: 0.3063 - iou: 0.1876 - recall_2: 0.9574 - precision_2: 0.4003 - val_loss: 0.8156 - val_dice_coef: 0.1911 - val_iou: 0.1058 - val_recall_2: 0.9227 - val_precision_2: 0.1557 - lr: 1.0000e-05\n","Epoch 12/20\n","12/12 [==============================] - ETA: 0s - loss: 0.6866 - dice_coef: 0.3129 - iou: 0.1958 - recall_2: 0.9543 - precision_2: 0.4240\n","Epoch 12: val_loss did not improve from 0.81564\n","12/12 [==============================] - 14s 1s/step - loss: 0.6866 - dice_coef: 0.3129 - iou: 0.1958 - recall_2: 0.9543 - precision_2: 0.4240 - val_loss: 0.8162 - val_dice_coef: 0.1570 - val_iou: 0.0873 - val_recall_2: 0.8796 - val_precision_2: 0.1879 - lr: 1.0000e-05\n","Epoch 13/20\n","12/12 [==============================] - ETA: 0s - loss: 0.6577 - dice_coef: 0.3446 - iou: 0.2150 - recall_2: 0.9585 - precision_2: 0.4778\n","Epoch 13: val_loss improved from 0.81564 to 0.79918, saving model to files/model.h5\n","12/12 [==============================] - 15s 1s/step - loss: 0.6577 - dice_coef: 0.3446 - iou: 0.2150 - recall_2: 0.9585 - precision_2: 0.4778 - val_loss: 0.7992 - val_dice_coef: 0.1889 - val_iou: 0.1047 - val_recall_2: 0.9126 - val_precision_2: 0.2261 - lr: 1.0000e-05\n","Epoch 14/20\n","12/12 [==============================] - ETA: 0s - loss: 0.6350 - dice_coef: 0.3678 - iou: 0.2297 - recall_2: 0.9600 - precision_2: 0.5182"]}]},{"cell_type":"code","source":["\"\"\"eval.py\"\"\"\n","\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","import numpy as np\n","import cv2\n","from glob import glob\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.utils import CustomObjectScope      # used to implement additional metrics such as iou, dice_coef, etc\n","\n","\"\"\" Directory for storing files \"\"\"\n","create_dir(\"results\")\n","\n","\"\"\" Loading model \"\"\"# define functions that are externmal to tensorflow\n","with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n","    model = tf.keras.models.load_model(\"files/model.h5\")\n","\n","for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n","        \"\"\" Extracing the image name. \"\"\"\n","        image_name = x.split(\"/\")[-1]\n","\n","        \"\"\" Reading the image \"\"\"       # 'read_image' function\n","        ori_x = cv2.imread(x, cv2.IMREAD_COLOR)\n","        ori_x = cv2.resize(ori_x, (W, H))\n","        x = ori_x/255.0\n","        x = x.astype(np.float32)\n","        x = np.expand_dims(x, axis=0)\n","\n","        \"\"\" Reading the mask \"\"\"        # 'read_mask' function\n","        ori_y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","        ori_y = cv2.resize(ori_y, (W, H))\n","        ori_y = np.expand_dims(ori_y, axis=-1)  ## (512, 512, 1)\n","        ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)  ## (512, 512, 3)\n","\n","        \"\"\" Predicting the mask. \"\"\"\n","        y_pred = model.predict(x)[0]> 0.5\n","        y_pred = y_pred.astype(np.int32)        # converting predicted result to integer datatype\n","\n","        y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n","\n","        \"\"\" Saving the predicted mask along with the image and GT \"\"\"\n","        save_image_path = f\"results/{image_name}\"   # location to save image\n","\n","        sep_line = np.ones((H, 10, 3)) * 255    # a white line with 10 pivel width\n","\n","        cat_image = np.concatenate([ori_x, sep_line, ori_y, sep_line, y_pred*255], axis=1)  # original image | original mask | predicted mask [ori_x, sep_line, ori_y, sep_line, y_pred*255]\n","\n","        cv2.imwrite(save_image_path, cat_image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iZ3FRDBrZ8M","executionInfo":{"status":"ok","timestamp":1687456566580,"user_tz":-330,"elapsed":18822,"user":{"displayName":"John F Aradan","userId":"10714156417061867226"}},"outputId":"80354821-af7a-4eed-898f-05860cd0f301"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/6 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 5s 5s/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 1/6 [00:06<00:33,  6.71s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 2/6 [00:08<00:15,  3.89s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 3/6 [00:11<00:10,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 4/6 [00:13<00:06,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 5/6 [00:15<00:02,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6/6 [00:17<00:00,  2.95s/it]\n"]}]}]}